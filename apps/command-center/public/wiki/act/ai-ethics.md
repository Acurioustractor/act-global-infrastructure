---
title: "AI Agent Strategy"
slug: ai-ethics
status: published
last_updated: 2026-02-04
---

# AI Agent Strategy (Aligned to ALMA)

AI agents must align with ALMA and Empathy Ledger consent. The point is not automation at all costs, but ethical intelligence that protects community sovereignty.

---

## Core Principle

> The best AI output is the one that gets out of the way and lets the right voice be heard.

AI serves community voice. It never replaces it.

---

## Non-Negotiables

| Rule | Enforcement |
|------|-------------|
| **Cultural sovereignty is sacred** | OCAP enforced in code and practice |
| **No individual profiling** | System-level patterns only |
| **Sacred knowledge hard-blocked** | Cannot be processed, not just warned |
| **Community authority highest weight** | Overrides efficiency in decision paths |
| **Consent before analysis** | No opt-out model, explicit opt-in only |

---

## ALMA as Gatekeeper

ALMA gatekeeps all AI learning and ethics checks:

```
User/Community Input
        ↓
   ALMA Check
   - Consent verified?
   - Cultural sensitivity flagged?
   - Authority confirmed?
        ↓
   AI Processing (if permitted)
        ↓
   ALMA Review
   - Output safe?
   - Individual profiling avoided?
   - Value returned to community?
        ↓
   Community Review
        ↓
   Output
```

---

## What AI Can Do

| Task | Permitted | Conditions |
|------|-----------|------------|
| Summarize meetings | Yes | Consent from participants |
| Map relationships between projects | Yes | System-level only |
| Check consent scope before release | Yes | Automated gatekeeping |
| Draft content for review | Yes | Human review required |
| Assist with research synthesis | Yes | Attribution maintained |

---

## What AI Cannot Do

| Task | Reason |
|------|--------|
| Profile, rank, or optimize individuals | Dignity violation |
| Override community voice | Authority breach |
| Process sacred content | Cultural sovereignty |
| Generate final narratives | Human authority required |
| Make consent decisions | Community authority only |
| Analyze without explicit opt-in | Consent violation |

---

## Agent Roles (Internal)

| Agent | Role | Guardrails |
|-------|------|------------|
| **Scribe** | Summarizes meetings, captures next actions | Consent from participants, no profiling |
| **Cartographer** | Maps relationships between projects, stories, signals | System-level patterns only |
| **Evidence Steward** | Checks consent scope and shareability | Cannot override community decisions |
| **Studio Assistant** | Supports drafting and editing | Never owns the narrative |
| **Farmhand** | Orchestrates tasks, turns messy inputs into actions | ALMA checks on all outputs |

---

## AI Assistance Boundaries

### Synthesis and Diagrams
- AI can assist with early exploration
- Draft diagrams and summaries permitted
- Final outputs require human and community review

### Voice and Content
- ACT Voice tools must pass alignment checks
- Cannot override lived experience
- Support, not replace, community storytelling

---

## Farmhand Role

Farmhand turns messy inputs into clear next actions across the Knowledge Hub:

**Farmhand Can:**
- Turn messy inputs into clear tasks
- Protect consent and cultural boundaries in summaries
- Connect LCAA steps to real work
- Keep ALMA signals visible

**Farmhand Cannot:**
- Profile individuals
- Override community voice
- Inflate claims or certainty
- Process without consent

> Field note: Intelligence without consent is just extraction. We would rather be slower than wrong.

---

## Implementation Checklist

For any AI feature:

| Check | Status |
|-------|--------|
| OCAP principles respected? | ☐ |
| ALMA gatekeeper integrated? | ☐ |
| Individual profiling prevented? | ☐ |
| Sacred content hard-blocked? | ☐ |
| Community authority preserved? | ☐ |
| Opt-in consent required? | ☐ |
| Human review on outputs? | ☐ |

---

## Future Development

As AI capabilities grow, we maintain:

1. **Community veto** — Any AI use can be blocked
2. **Transparency** — What AI does is visible
3. **Accountability** — Humans answer for AI outputs
4. **Reversibility** — AI decisions can be undone
5. **Locality** — Prefer local/open models where possible

---

*See also: [ALMA Framework](/wiki/act/alma) | [Governance & Consent](/wiki/act/governance) | [Empathy Ledger](/wiki/empathy-ledger)*
